{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from gerrychain import Graph, GeographicPartition, Partition, Election, accept\n",
    "from gerrychain.updaters import Tally, cut_edges\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from gerrychain.random import random\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from gerrychain import MarkovChain\n",
    "from gerrychain.constraints import single_flip_contiguous\n",
    "from gerrychain.proposals import recom, propose_random_flip\n",
    "from gerrychain.accept import always_accept\n",
    "from gerrychain.metrics import polsby_popper\n",
    "from gerrychain import constraints\n",
    "from gerrychain.constraints import no_vanishing_districts\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas\n",
    "import math\n",
    "from itertools import combinations_with_replacement\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile = \"https://github.com/mggg-states/PA-shapefiles/raw/master/PA/PA_VTD.zip\"\n",
    "\n",
    "df = gpd.read_file(shapefile)\n",
    "\n",
    "#For Pennsylvania\n",
    "county_col = \"COUNTYFP10\"\n",
    "pop_col = \"TOT_POP\"\n",
    "uid = \"GEOID10\"\n",
    "\n",
    "graph = Graph.from_geodataframe(df,ignore_errors=True)\n",
    "graph.add_data(df,list(df))\n",
    "graph = nx.relabel_nodes(graph, df[uid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locality_splits_dict(partition, locality_col, df):\n",
    "    \"\"\"\n",
    "    From a partition, generates a dictionary of counter dictionaries.\n",
    "\n",
    "    :param partition: The partition for which a dictionary is being generated.\n",
    "\n",
    "    :return: A dictionary with keys as dictrict numbers and values as Counter() dictionaries. These counter dictionaries have pairs County_ID: NUM which counts the number of VTDs in the county in the district. \n",
    "    \"\"\"\n",
    "    localitydict = dict(graph.nodes(data=locality_col))\n",
    "    localities = (set(list(df[locality_col])))\n",
    "\n",
    "    locality_splits = {k:[] for k in localities}\n",
    "    locality_splits = {k:[localitydict[v] for v in d] for k,d in partition.assignment.parts.items()}\n",
    "    locality_splits = {k: Counter(v) for k,v in locality_splits.items()}\n",
    "    return locality_splits, localities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_splits(partition, locality_col, df):\n",
    "    \"\"\"\n",
    "    Calculates the number of counties in 2 or more districts.\n",
    "\n",
    "    :param partition: The partition to be scored.\n",
    "\n",
    "    :return: The number of splittings in the partition\n",
    "    \"\"\"\n",
    "    locality_splits, localities = locality_splits_dict(partition, locality_col, df)\n",
    "\n",
    "    counter = 0\n",
    "    for district in locality_splits.keys():\n",
    "        counter += len(locality_splits[district])\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_edges_in_district(partition, graph):\n",
    "    \"\"\"\n",
    "    Computes a ratio of the cut edges between two counties over the total number of cut edges.\n",
    "\n",
    "    :param partition: the partition to be scored.\n",
    "\n",
    "    return The ratio of cut edges between two counties over the total number of cut edges.\n",
    "    \"\"\"\n",
    "    countydict = dict(graph.nodes(data=county_col))\n",
    "\n",
    "    cut_edges_between = 0\n",
    "    cut_edge_set = partition[\"cut_edges\"]\n",
    "    for i in cut_edge_set:\n",
    "        vtd_1 = i[0]\n",
    "        vtd_2 = i[1]\n",
    "        county_1 = countydict.get(vtd_1)\n",
    "        county_2 = countydict.get(vtd_2)\n",
    "        if county_1 != county_2:\n",
    "            cut_edges_between += 1\n",
    "    num_cut_edges = len(cut_edge_set)\n",
    "    score = cut_edges_between/num_cut_edges\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_partition = GeographicPartition(\n",
    "    graph,\n",
    "    assignment=\"2011_PLA_1\",\n",
    "    updaters={\n",
    "        \"polsby_popper\" : polsby_popper,\n",
    "        \"cut_edges\": cut_edges,\n",
    "        \"population\": Tally(pop_col, alias=\"population\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "0.32952138924184665\n"
     ]
    }
   ],
   "source": [
    "print(num_splits(starting_partition, county_col, df))\n",
    "print(cut_edges_in_district(starting_partition, graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vtds_per_district(locality_splits):\n",
    "    \"\"\"\n",
    "    A function that counts the number of VTDs per district.\n",
    "    \n",
    "    :param county_splits: A dictionary with keys as district numbers and values Counter() dictionaries. The Counter dictionaries have pairs COUNTY_ID: NUM which counts the number of VTDS in the county in the district.\n",
    "        \n",
    "    :return: The total number of vtds in a district.\n",
    "    \"\"\"\n",
    "    \n",
    "    vtds = {}\n",
    "    \n",
    "    for district in locality_splits.keys():\n",
    "        sum = 0\n",
    "        counter = locality_splits[district]\n",
    "        for vtd in counter.values():\n",
    "            sum += vtd\n",
    "        vtds[district] = sum\n",
    "    return vtds \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_entropy(partition, locality_col, df):\n",
    "    '''\n",
    "    Computes the shannon entropy score of a district plan.\n",
    "    \n",
    "    :param partition: The partition to be scored.\n",
    "    :param locality_col: The string of the locality column's name. \n",
    "    :param df: A dataframe of the state shapefile.\n",
    "\n",
    "    :returns: Shannon entropy score.\n",
    "    '''\n",
    "    locality_splits, localities = locality_splits_dict(partition, locality_col, df)\n",
    "    vtds = vtds_per_district(locality_splits) \n",
    "    num_districts = len(locality_splits.keys())\n",
    "\n",
    "    total_vtds = 0\n",
    "    for k,v in locality_splits.items():\n",
    "        for x in list(v.values()):\n",
    "            total_vtds += x\n",
    "\n",
    "    entropy = 0\n",
    "    for locality_j in localities:         #iter thru localities to get total count\n",
    "        tot_county_vtds = 0\n",
    "        #iter thru counters\n",
    "        for k,v in locality_splits.items():\n",
    "            v = dict(v)\n",
    "            if locality_j in list(v.keys()):\n",
    "                tot_county_vtds += v[locality_j]\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        inner_sum = 0\n",
    "        q = tot_county_vtds / total_vtds\n",
    "        \n",
    "        #iter thru districts to get vtds in county in district\n",
    "        for district in range(num_districts):            \n",
    "            counter = dict(locality_splits[district+1])            \n",
    "            if locality_j in counter:\n",
    "                intersection = counter[str(locality_j)]\n",
    "                p = intersection / tot_county_vtds\n",
    "\n",
    "                if p != 0:\n",
    "                    inner_sum += p * math.log(1/p)\n",
    "            else: \n",
    "                continue\n",
    "        entropy += q * (inner_sum)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6450986297841543"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shannon_entropy(starting_partition, county_col, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
